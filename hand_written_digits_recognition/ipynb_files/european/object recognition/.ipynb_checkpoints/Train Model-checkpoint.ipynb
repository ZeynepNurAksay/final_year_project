{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0c4a0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieves data_dict dictionary from Export_European_Digit_Dataset file\n",
    "%store -r data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cb3d021",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-03 22:21:50.057269: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# necessary imports\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc82f62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the below variables are for training images, training labels, testing images and testing labels in order\n",
    "x_train = data_dict['training_images']\n",
    "y_train = data_dict['training_labels']\n",
    "x_test = data_dict['testing_images']\n",
    "y_test = data_dict['testing_labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb6147dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# prints out the shape of image arrays\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15b84f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshapes array to (length of the array, 28, 28, 1). Here 1 refers to gray scale images\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8080337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# prints out the shape of the image arrays\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "610a7ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalisation of the training images\n",
    "x_train = x_train.astype('float32')\n",
    "x_train = x_train/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d41ceff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalisation of the testing images\n",
    "x_test = x_test.astype('float32')\n",
    "x_test = x_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2dde835f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 0 4 ... 5 6 8]\n",
      "[7 2 1 ... 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "# prints out the label arrays\n",
    "print(y_train)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "745d0ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-03 22:22:09.652111: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# the model creation\n",
    "# the CNN model for this software is sequential\n",
    "model = Sequential()\n",
    "# it has 3 convolutional layers and 3 max pooling layers.\n",
    "# for convolutional layers 3x3 filter is applied to input images\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', input_shape = (28, 28, 1)))\n",
    "# for the max pooling layers the max value from 2x2 areas is chosen\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "# the output image from above layers is flattened\n",
    "model.add(Flatten())\n",
    "# the number of nodes are decreased to 10 by three steps\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ce92237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 64)        640       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 13, 13, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 11, 11, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 5, 5, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 3, 3, 64)          36928     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 1, 1, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 81,066\n",
      "Trainable params: 81,066\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# visual summary of the created model. Each change can be seen clearly in the below table\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4e3218c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compiles the model\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "846eb156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1313/1313 [==============================] - 18s 14ms/step - loss: 0.2836 - accuracy: 0.9091 - val_loss: 0.1071 - val_accuracy: 0.9669\n",
      "Epoch 2/10\n",
      "1313/1313 [==============================] - 18s 14ms/step - loss: 0.0928 - accuracy: 0.9721 - val_loss: 0.0822 - val_accuracy: 0.9756\n",
      "Epoch 3/10\n",
      "1313/1313 [==============================] - 18s 13ms/step - loss: 0.0692 - accuracy: 0.9789 - val_loss: 0.0756 - val_accuracy: 0.9762\n",
      "Epoch 4/10\n",
      "1313/1313 [==============================] - 18s 14ms/step - loss: 0.0538 - accuracy: 0.9836 - val_loss: 0.0593 - val_accuracy: 0.9817\n",
      "Epoch 5/10\n",
      "1313/1313 [==============================] - 19s 14ms/step - loss: 0.0422 - accuracy: 0.9869 - val_loss: 0.0523 - val_accuracy: 0.9850\n",
      "Epoch 6/10\n",
      "1313/1313 [==============================] - 19s 15ms/step - loss: 0.0369 - accuracy: 0.9888 - val_loss: 0.0589 - val_accuracy: 0.9826\n",
      "Epoch 7/10\n",
      "1313/1313 [==============================] - 19s 15ms/step - loss: 0.0327 - accuracy: 0.9896 - val_loss: 0.0683 - val_accuracy: 0.9806\n",
      "Epoch 8/10\n",
      "1313/1313 [==============================] - 20s 15ms/step - loss: 0.0261 - accuracy: 0.9916 - val_loss: 0.0559 - val_accuracy: 0.9843\n",
      "Epoch 9/10\n",
      "1313/1313 [==============================] - 20s 15ms/step - loss: 0.0227 - accuracy: 0.9926 - val_loss: 0.0637 - val_accuracy: 0.9832\n",
      "Epoch 10/10\n",
      "1313/1313 [==============================] - 21s 16ms/step - loss: 0.0193 - accuracy: 0.9938 - val_loss: 0.0578 - val_accuracy: 0.9849\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f92fd6da3e0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trains the model\n",
    "model.fit(x_train, y_train, epochs=10, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20266231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 5ms/step - loss: 0.0561 - accuracy: 0.9872\n",
      "0.056142982095479965\n",
      "0.9872000217437744\n"
     ]
    }
   ],
   "source": [
    "# evaluates the model with the testing data\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print(test_loss)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "42073f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saves model to mnist.h5 file in order to be able to use the weightings in website\n",
    "model.save('mnist.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "883fc05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('mnist.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9ac8cd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "#resize image to 28x28 pixels\n",
    "img = cv2.imread('image.jpeg')\n",
    "img = cv2.resize(img, (28, 28), interpolation = cv2.INTER_AREA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7e22bd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#convert rgb to grayscale\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "img = np.array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4efd5450",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshaping to support our model input and normalizing\n",
    "img = img.reshape(1,28,28,1)\n",
    "img = img/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ab92cdee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 26ms/step\n",
      "1\n",
      "0.41177157\n"
     ]
    }
   ],
   "source": [
    "#predicting the class\n",
    "res = model.predict([img])[0]\n",
    "print(np.argmax(res))\n",
    "print(max(res)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
